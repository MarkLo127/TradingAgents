# -*- coding: utf-8 -*-
import time
import json


def create_research_manager(llm, memory):
    """
    å»ºç«‹ä¸€å€‹ç ”ç©¶ç®¡ç†å“¡ï¼ˆè£åˆ¤ï¼‰ç¯€é»ã€‚

    é€™å€‹ç¯€é»æ‰®æ¼”æŠ•è³‡çµ„åˆç¶“ç†å’Œè¾¯è«–ä¸»æŒäººçš„è§’è‰²ã€‚
    å…¶ä»»å‹™æ˜¯è©•ä¼°çœ‹æ¼²å’Œçœ‹è·Œåˆ†æå¸«ä¹‹é–“çš„è¾¯è«–ï¼Œä¸¦åšå‡ºæœ€çµ‚çš„æŠ•è³‡æ±ºç­–
    ï¼ˆèˆ‡çœ‹è·Œæ–¹ä¸€è‡´ã€èˆ‡çœ‹æ¼²æ–¹ä¸€è‡´ï¼Œæˆ–åœ¨æœ‰å……åˆ†ç†ç”±æ™‚é¸æ“‡æŒæœ‰ï¼‰ã€‚
    å®ƒé‚„éœ€è¦åˆ¶å®šä¸€å€‹è©³ç´°çš„æŠ•è³‡è¨ˆç•«çµ¦äº¤æ˜“å“¡ã€‚

    Args:
        llm: ç”¨æ–¼ç”Ÿæˆæ±ºç­–å’Œè¨ˆç•«çš„èªè¨€æ¨¡å‹ã€‚
        memory: å„²å­˜éå»æƒ…æ³å’Œåæ€çš„è¨˜æ†¶é«”ç‰©ä»¶ã€‚

    Returns:
        function: ä¸€å€‹ä»£è¡¨ç ”ç©¶ç®¡ç†å“¡ç¯€é»çš„å‡½å¼ï¼Œå¯åœ¨ langgraph ä¸­ä½¿ç”¨ã€‚
    """

    def research_manager_node(state) -> dict:
        """
        ç ”ç©¶ç®¡ç†å“¡ç¯€é»çš„åŸ·è¡Œå‡½å¼ã€‚

        Args:
            state (dict): ç•¶å‰çš„åœ–ç‹€æ…‹ã€‚

        Returns:
            dict: æ›´æ–°å¾Œçš„ç‹€æ…‹ï¼ŒåŒ…å«è£åˆ¤çš„æ±ºç­–å’ŒæŠ•è³‡è¨ˆç•«ã€‚
        """
        # å¾ç‹€æ…‹ä¸­ç²å–æ‰€éœ€è³‡è¨Š
        investment_debate_state = state["investment_debate_state"]
        history = investment_debate_state.get("history", "")
        
        market_research_report = state["market_report"]
        sentiment_report = state["sentiment_report"]
        news_report = state["news_report"]
        fundamentals_report = state["fundamentals_report"]

        # å®šç¾©æ–‡æœ¬æˆªæ–·å‡½æ•¸ä»¥é¿å…è¶…é token é™åˆ¶
        def truncate_text(text, max_chars):
            """æˆªæ–·æ–‡æœ¬åˆ°æŒ‡å®šå­—ç¬¦æ•¸"""
            if len(text) <= max_chars:
                return text
            return text[:max_chars] + "\n...(å…§å®¹å·²æˆªæ–·)"
        
        # ç‚ºæ¯å€‹å ±å‘Šè¨­ç½®åˆç†çš„å­—ç¬¦é™åˆ¶
        # æ¨¡å‹ gpt-5-mini çš„é™åˆ¶æ˜¯ 8192 tokens
        # æ··åˆä¸­è‹±æ–‡ä¼°ç®—: 1 å­—ç¬¦ â‰ˆ 1.5-2 tokens (å–ä¿å®ˆå€¼)
        # ç›®æ¨™: ç¸½å­—ç¬¦æ•¸ < 3500 å­—ç¬¦ (ç´„ 5250-7000 tokensï¼Œç•™è¶³å¤  tokens çµ¦ completion)
        market_research_report = truncate_text(market_research_report, 500)
        sentiment_report = truncate_text(sentiment_report, 500)
        news_report = truncate_text(news_report, 600)
        fundamentals_report = truncate_text(fundamentals_report, 600)
        
        # æ•´åˆç•¶å‰æƒ…æ³
        curr_situation = f"{market_research_report}\n\n{sentiment_report}\n\n{news_report}\n\n{fundamentals_report}"
        
        # å¾è¨˜æ†¶é«”ä¸­ç²å–éå»ç›¸ä¼¼æƒ…æ³çš„ç¶“é©—
        past_memories = memory.get_memories(curr_situation, n_matches=2)

        # å°‡éå»çš„ç¶“é©—æ ¼å¼åŒ–ç‚ºå­—ä¸²ï¼ˆé™åˆ¶é•·åº¦ï¼‰
        past_memory_str = ""
        for i, rec in enumerate(past_memories, 1):
            recommendation = rec["recommendation"]
            # é™åˆ¶æ¯æ¢è¨˜æ†¶çš„é•·åº¦
            if len(recommendation) > 200:
                recommendation = recommendation[:200] + "...(å·²æˆªæ–·)"
            past_memory_str += recommendation + "\n\n"
        
        # æˆªæ–·è¾¯è«–æ­·å² - é€™æ˜¯æœ€å®¹æ˜“è¶…éé™åˆ¶çš„éƒ¨åˆ†
        # é™åˆ¶è¾¯è«–æ­·å²åœ¨ 1200 å­—ç¬¦ä»¥å…§
        history = truncate_text(history, 1200)

        # å»ºç«‹æç¤º (prompt)
        prompt = f"""**é‡è¦ï¼šæ‚¨å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼ˆTraditional Chineseï¼‰å›è¦†æ‰€æœ‰å…§å®¹ã€‚**

ã€å°ˆæ¥­èº«ä»½ã€‘
æ‚¨æ˜¯æŠ•è³‡æ±ºç­–ç¶“ç†ï¼Œè² è²¬è©•ä¼°å¤šç©ºè¾¯è«–ä¸¦åšå‡ºæœ€çµ‚æŠ•è³‡æ±ºç­–ã€‚**æ‚¨å¿…é ˆä¿æŒåš´æ ¼ä¸­ç«‹è§€é»ï¼Œå…¬æ­£è©•ä¼°çœ‹æ¼²èˆ‡çœ‹è·Œé›™æ–¹è«–æ“šï¼ŒåŸºæ–¼è­‰æ“šåšå‡ºç¨ç«‹æ±ºç­–ã€‚**

ã€è·è²¬ã€‘
1. **è©•ä¼°è«–è­‰**ï¼šå®¢è§€æ¬Šè¡¡çœ‹æ¼²èˆ‡çœ‹è·Œæ–¹çš„è«–æ“šå¼·åº¦ï¼Œä¸åè¢’ä»»ä½•ä¸€æ–¹
2. **åšå‡ºæ±ºç­–**ï¼šåŸºæ–¼è­‰æ“šæ˜ç¢ºåˆ¤æ–·è²·å…¥/è³£å‡º/æŒæœ‰ï¼Œå±•ç¾ç¨ç«‹åˆ¤æ–·
3. **åˆ¶å®šè¨ˆç•«**ï¼šæä¾›äº¤æ˜“å“¡å¯åŸ·è¡Œçš„è©³ç´°æ“ä½œæŒ‡å¼•
4. **ä¸­ç«‹è£åˆ¤**ï¼š**ä½œç‚ºä¸­ç«‹è£åˆ¤ï¼Œç¶œåˆé›™æ–¹è«–é»å¾Œåšå‡ºç¨ç«‹æ±ºç­–ï¼Œä¸å—ä»»ä½•ä¸€æ–¹å½±éŸ¿**

ã€å¯ç”¨è³‡è¨Šã€‘
- éå»åæ€ï¼š"{past_memory_str}"
- è¾¯è«–æ­·å²ï¼š{history}

ã€è¼¸å‡ºè¦æ±‚ã€‘
**å­—æ•¸è¦æ±‚**ï¼š**è‡³å°‘800å­—ä»¥ä¸Š**
**å…§å®¹çµæ§‹**ï¼š
1. æ±ºç­–æ‘˜è¦ï¼ˆ150å­—ä»¥ä¸Šï¼‰ï¼šæ˜ç¢ºçš„è²·å…¥/è³£å‡º/æŒæœ‰æ±ºç­–èˆ‡æ ¸å¿ƒç†ç”±
2. è«–è­‰è©•ä¼°ï¼ˆ200å­—ä»¥ä¸Šï¼‰ï¼šå…¬æ­£è©•ä¼°é›™æ–¹æœ€å¼·è«–é»èˆ‡åˆ†æ­§é»ï¼Œä¸åè¢’ä»»ä½•ä¸€æ–¹
3. æ±ºç­–ä¾æ“šï¼ˆ300å­—ä»¥ä¸Šï¼‰ï¼šé¸æ“‡æ­¤ç«‹å ´çš„é—œéµè­‰æ“šèˆ‡é‚è¼¯æ¨ç†
4. æ“ä½œæŒ‡å¼•ï¼ˆ100å­—ä»¥ä¸Šï¼‰ï¼šéƒ¨ä½è¦æ¨¡ã€ç›®æ¨™åƒ¹ä½ã€åœæè¨­å®šç­‰å…·é«”åƒæ•¸
5. é¢¨éšªæç¤ºï¼ˆ50å­—ä»¥ä¸Šï¼‰ï¼šä¸»è¦é¢¨éšªèˆ‡ç›£æ§é‡é»

**æ’°å¯«åŸå‰‡**ï¼š
- **åš´æ ¼ä¸­ç«‹**ï¼šä½œç‚ºä¸­ç«‹è£åˆ¤ï¼Œä¸åå‘çœ‹æ¼²æˆ–çœ‹è·Œä»»ä½•ä¸€æ–¹
- **ç¨ç«‹æ±ºç­–**ï¼šåŸºæ–¼è­‰æ“šèˆ‡é‚è¼¯åšå‡ºç¨ç«‹åˆ¤æ–·ï¼Œå±•ç¾æ±ºç­–è‡ªä¸»æ€§
- æ±ºç­–æ˜ç¢ºï¼Œé¿å…æ¨¡ç¨œå…©å¯ï¼Œå¿…é ˆçµ¦å‡ºæ¸…æ™°ç«‹å ´
- æä¾›å…·é«”é‡åŒ–çš„æ“ä½œåƒæ•¸ï¼Œç¢ºä¿å¯åŸ·è¡Œæ€§
- é‚è¼¯æ¸…æ™°ï¼Œè­‰æ“šå……åˆ†ï¼ŒèªªæœåŠ›å¼·

**çµå°¾æç¤º**ï¼š
è«‹åœ¨å ±å‘Šæœ€å¾ŒåŠ ä¸Šä»¥ä¸‹çµå°¾ï¼š
ã€Œ---
ğŸ‘” **æœ¬å ±å‘Šç‚ºç ”ç©¶ç¶“ç†çš„æŠ•è³‡æ±ºç­–ï¼Œç¶œåˆçœ‹æ¼²èˆ‡çœ‹è·Œé›™æ–¹è«–æ“šå¾Œåšå‡ºã€‚å»ºè­°äº¤æ˜“åœ˜éšŠåŸ·è¡Œå‰å†æ¬¡ç¢ºèªå¸‚å ´ç‹€æ³ã€‚æŠ•è³‡æ±ºç­–éœ€ç¨ç«‹åˆ¤æ–·ï¼Œè«‹è¬¹æ…è©•ä¼°ã€‚**ã€

è«‹æä¾›å°ˆæ¥­ä¸”å¯åŸ·è¡Œçš„æŠ•è³‡æ±ºç­–å ±å‘Šã€‚"""
        
        
        # å‘¼å« LLM ç”Ÿæˆå›æ‡‰
        response = llm.invoke(prompt)

        # æ›´æ–°æŠ•è³‡è¾¯è«–ç‹€æ…‹
        new_investment_debate_state = {
            "judge_decision": response.content,
            "history": investment_debate_state.get("history", ""),
            "bear_history": investment_debate_state.get("bear_history", ""),
            "bull_history": investment_debate_state.get("bull_history", ""),
            "current_response": response.content,
            "count": investment_debate_state["count"],
        }

        # è¿”å›æ›´æ–°å¾Œçš„ç‹€æ…‹ï¼ŒåŒ…æ‹¬è£åˆ¤çš„æ±ºç­–å’ŒæŠ•è³‡è¨ˆç•«
        return {
            "investment_debate_state": new_investment_debate_state,
            "investment_plan": response.content,
        }

    return research_manager_node